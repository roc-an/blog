# 一段话说透一个前端知识点 - 网络请求

## 什么是 CDN？

浏览器和服务器是 HTTP 协议的两个端点，中间会经过“重重关卡”，其中一个重要角色就是 CDN

**CDN**，全称是 Content Delivery Network，翻译过来就是“内容分发网络”。它应用了 HTTP 协议里缓存和代理的技术，代替源站响应客户端的请求

CDN 的优势：

可以缓存源站数据，让浏览器的请求不用“千里迢迢”到达源站服务器，直接在“半路”就可以获取响应。如果 CDN 的调度算法很优秀，更可以找到离用户最近的节点，大幅度缩短响应时间

CDN 是现在互联网中的一项重要基础设施，提供了诸多功能：

* 网络加速
* 负载均衡
* 安全防护
* 边缘计算
* 跨运营商网络

很多云服务商都将 CDN 作为产品的一部分

## TCP/IP 网络分层模型

**TCP/IP 协议总共有四层**，就像搭积木一样，每一层需要下层的支撑，同时又支撑着上层，任何一层被抽掉都可能会导致整个协议栈坍塌

层次顺序是“从下往上”数的，所以第一层就是最下面的一层：

1. 链接层（Link Layer）：负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层
2. 网际层，或者叫网络互连层（Internet Layer）：IP 协议就处在这一层。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了
3. 传输层（Transport Layer）：这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP
4. 应用层（Application Layer）：有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 HTTP

## TCP VS UDP

连接有无状态：

* TCP 是一个有状态的协议，需要先与对方建立连接后才能发送数据，而且保证数据不丢失、不重复
* UDP 无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发送到对方

数据的形式：

* TCP 的数据是连续的“字节流”，有先后顺序
* UDP 是分散的小数据包，是顺序发，乱序收

## HTTP 常见状态码有哪些？

状态码分类：

* 1xx：服务器收到请求：服务器收到了前端发送的请求，但还没返回
* 2xx：请求成功
* 3xx：重定向：服务端告知客户端去其他地址访问
* 4xx：客户端错误
* 5xx：服务端错误

常见状态码：

* 200：请求成功，服务端把成功的资源返回

* 301：永久重定向（配合 `Response Header` 的 `Location` 字段新地址，浏览器自动处理）：之后再次访问该地址，直接用 `location` 跳转新地址
  * 适用于网站域名到期，或者想换域名了，这时候访问老域名，返回 301 并 `location` 是新域名
* 302：临时重定向（配合 `Response Header` 的 `Location` 字段新地址，浏览器自动处理）：仅本次会重定向
  * 比如搜索引擎、邮箱、知乎、短网址等等，都是先跳转自己的域名，再跳转到其他目标域名
* 304：资源未被修改：向服务端请求资源，该资源之前客户端已经请求过了，没过期，可以使用客户端缓存

* 403：没有权限：比如没登录、没有对应的角色权限
* 404：资源未找到

* 500：服务器错误
* 504：网关超时：能访问通服务器，多台服务器跳转处理时可能超时了

## HTTP 方法有哪些？

* GET：获取服务器数据
* POST：向服务器新建数据
* PATCH/PUT：更新数据
* DELETE：删除数据

## 什么是 Restful API？

Restful API 是一种 API **设计方法**。**Restful API 把每个 URL 当做一个唯一的资源标识**。

* 用 HTTP 请求方法表示操作类型：
  * POST 请求 `/api/blog`，新建博客
  * GET 请求 `/api/blog/100`，获取 ID 为 `100` 的博客
  * PATCH 请求 `api/blog/100`，更新 ID 为 `100` 的博客
* 尽量不用 URL 参数：
  * 传统 API 设计：`/api/list?pageIndex=2`，更像是功能，请求页数为 2 `list` 数据
  * Restful API 设计：`/api/list/2`，把 `list` 当作资源

## HTTP 有哪些常见的 Header？

常见的请求头 Request Header：

* `Accept`： 浏览器可接收的数据格式
* `Accept-Encoding`：浏览器可接收的压缩算法，比如 gzip。服务器按此格式进行数据压缩，浏览器收到数据后解压缩
* `Accept-Language`：浏览器可接收的语言，比如 zh-CN
* `Connection: keep-alive`：一次 TCP 连接可重复使用
  * HTTP 是单次无状态连接，每次请求都连接一次是比较消耗资源的，HTTP2 支持 Keep Alive，客户端与服务器建立连接后可以重复使用该连接
* `Cookie`：每次同域请求资源都会带上
* `Host`：请求的服务器域名
* `User-Agent`：简称 UA，浏览器信息
* `Content-Type`：发送数据的格式，如 `application/json`，一般用于 POST 请求

常见的响应头 Response Header：

* `Content-Type`：返回数据的格式，如 `application/json`
* `Content-Length`：返回数据的大小，多少字节
* `Content-Encoding`：返回数据的压缩算法，如 gzip。告诉浏览器数据使用什么算法压缩的
* `Set-Cookie`：服务端通过该字段设置或更改 Cookie

客户端、服务器也可以自定义 Header。比如使用 axios 自定义 header 的配置项：

```js
headers: { 'X-Requested-With': 'XMLHttpRequest' }
```

Header 的 `key` 和 `value` 都是可以自定义的。比如有些接口需要在 Header 中加一些秘钥或是特定的值来证明身份

## HTTP 缓存机制？

为什么需要缓存？

* 计算机的计算能力越来越强，往往避免和优化不了的，就是网络请求。网络请求的加载，相比于 CPU 的计算或页面的渲染是更慢的
* 网络请求是不稳定的，弱网或无网环境很难请求到数据

哪些资源可以被缓存？

* 静态资源：CSS、JS、图片

哪些资源不会被缓存？

* 网站的 HTML 一般不会被缓存，因为存在更新，所以要替换模板
* 业务数据不应被缓存

### HTTP 缓存策略（强制缓存 VS 协商缓存）

#### 强制缓存

**初次请求**：

浏览器初次请求服务器，服务器会返回所请求的资源，并且：
  * 如果服务器认为该资源可以被缓存，**响应头（Response Header）就返回 `Catch-Control`**
  * 如果服务器认为该资源不应被缓存，响应头（Response Header）不返回 `Catch-Control`

如果服务端设置了 `Catch-Control`，那么浏览器会将资源缓存起来。

`Catch-Control` 字段：

* 位于响应头 Response Header 中，由服务器端设置
* 该字段**控制强制缓存的逻辑**
* 例如 `Catch-Control: max-age=3153600`，单位是秒

**再次请求**：

* 判断 `Catch-Control` 的 `max-age` 时间是否过期（也就是判断缓存的资源是否过期）：
  * 如果没过期，那么浏览器在「本地缓存」中查找资源，如果本地缓存中有就不会请求服务器
  * 如果缓存过期，浏览器会再次请求服务端

由于缓存的资源是否过期是由浏览器发请求前判断的，所以**强制缓存是一种浏览器缓存策略**。

`Catch-Control` 字段有哪些值：

* `max-age`（常用）：最大过期时间
* `no-catch`（常用）：浏览器本地不缓存该资源，浏览器应正常地去向服务器请求，服务器做处理
* `no-store`：不用浏览器本地缓存，也不用服务端的缓存措施，也就是每次请求服务器不做其他缓存处理，简单粗暴地把资源返回给浏览器
* `private`：只允许最终用户进行缓存，比如 PC 客户端、PC 浏览器、手机浏览器等等
* `public`：不仅允许最终用户进行缓存，还允许中间过程中的路由、代理进行缓存

`Expires` 字段：

* 它也是处于响应头 Response Header 中
* 它也用于控制缓存过期
* 是旧标准中的字段，已被 `Catch-Control` 代替

目前浏览器兼容 `Catch-Control` 和 `Expires`，但以 `Catch-Control` 为优先

#### 协商缓存（对比缓存）

**协商缓存是一种服务器端缓存策略**，由服务端判断资源是否应该被缓存（意思并不是该资源缓存在服务端）。

要点：

* 是一种服务端缓存策略
* 服务器判断客户端资源，是否和服务器端资源一致
* 如果资源一致，就返回 304，不一致则返回 200 和最新资源

**初次请求**：

1. 浏览器发送请求给服务器
2. 服务器返回资源和「资源标识」

**再次请求**：

1. 浏览器的请求携带资源标识
2. 服务端根据资源标识，判断浏览器拥有的资源是不是和服务端最新资源一致：
  * 如果一致，返回 304
  * 如果不一致，返回 200 、最新资源、资源标识

由此，之所以叫协商缓存，或者对比缓存，所“协商”或“对比”的，是浏览器发请求携带的资源标识和服务器拥有的最新资源的资源标识是否一致，如果一致就返回 304，告知浏览器其本地缓存的资源是最新的，可用。

资源标识：

* 是最初由服务端返回的，在响应头 Response Header 中
* 有两种：
  * `Last-Modified`：资源的最后修改时间。例如：`Mon, 30 Dec 2019 17:42:38 GMT`
  * `Etag`：优先使用，资源的唯一标识（一个字符串，类似人类的指纹）。例如：`6bd9NvC2BFM:52726`
* 如果资源被重复生成，而内容不变，`Etag` 更准确

### 刷新操作方式的不同，对缓存的影响

3 种刷新操作：

* 正常操作：地址栏输入 URL，跳转链接，前进后退等
* 手动刷新：F5，点击刷新按钮，右击菜单刷新
* 强制刷新：Ctrl + F5

不同的刷新操作，对应不同的缓存策略：

* 正常操作：强制缓存有效，协商缓存有效
* 手动刷新：强制缓存失效，协商缓存有效
* 强制刷新：强制缓存失效，协商缓存失效

## HTTPS 的加密方式？

### HTTP VS HTTPS

* HTTP 是明文传输，敏感信息容易被中间劫持。比如邮箱、手机号、账号密码、短信验证码等敏感信息
* HTTPS = HTTP + 加密，劫持了也无法解密
* 现代浏览器已逐渐强制使用 HTTPS 协议

### 对称加密 VS 非对称加密

* 对称加密：一个 key 同时负责加密和解密。但如果 key 被劫持，也不够安全
* 非对称加密：需要用一对 key，私钥和公钥。数据经公钥加密后，只有私钥能解密。要点：
  * 客户端用公钥进行加密，服务端用私钥进行解密
  * 即使传输过程中，公钥被黑客劫持，由于没有服务器上的私钥，依然无法解密

由此，对称加密和非对称加密的主要区别是，对称加密仅用 1 个 key 加密解密，而非对称加密是用一对 key 进行加密解密。

**HTTPS 同时用到了这两种加密方式**：

1. 先以「非对称加密」方式生成一个 key，即客户端通过公钥对 key 进行加密，传给服务端后，服务端用私钥解密，得到 key。这一步是绝对安全的
2. 客户端、服务端同时都有了 key（第 1 步通过非对称加密传输的）。这个 key 作为对称加密的 key，后续客户端向服务端仅传递用 `key` 加密了的数据，而不用传 `key`，服务端用 `key` 进行解密

所以概括来说，HTTPS 先通过非对称加密得到 key，key 用于后续对称加密数据的加密和解密。

那干脆为什么不每次都使用非对称加密呢？之所以这样做是因为，非对称加密的计算成本 > 对称加密。所以仅 1 次用非对称加密让服务端拥有和客户端一致的 key 即可

### HTTPS 证书 - 规避中间人攻击

HTTPS 证书起到了备案的作用，为了防止中间人攻击。比如黑客自己有公钥和私钥，然后将传输过程中的数据调包，这样就能用自己的公钥和私钥进行加密和解密。

因此使用第三方证书（慎用免费、不合规的证书），浏览器可以对证书进行校验

使用 HTTPS 证书防止中间人攻击的要点：

* 「服务端」向「第三方机构」申请证书，证书包含着公钥、私钥
* 「浏览器」支持证书的校验工作
* 「浏览器」首次向「服务端」发请求时，「服务端」将证书信息返回给「浏览器」
* 之后，「浏览器」验证收到的证书是否合法
  * 如果合法，就走 HTTPS 非对称加密、对称加密流程
  * 如果不合法，会提示用户去判断，或给到用户一些建议

这种流程下，一旦中间人替换了证书，浏览器进行校验时，就会发现不是某第三方机构签发的证书，就会提示用户访问风险

概括 HTTPS 进行验证的流程：

1. 证书验证
2. 数据传输：
  * 非对称加密，确保客户端和服务端都有随机码 key
  * 对称加密，通过 key 进行对称加密传输所有数据

## HTTP/2

由于 HTTPS 在安全方面已经做的非常好了，所以 HTTP/2 的唯一目标就是**改进性能**

### 头部压缩

报文 Header 一般会携带许多固定的头字段：

* User Agent
* Cookie
* Accept
* Server

这些字段多达几百字节甚至上千字节，但 Body 却常只有几十字节，成了不折不扣的“大头儿子”

成千上万的请求响应报文里有很多字段是重复的，非常浪费，“长尾效应”导致大量带宽消耗在了这些冗余度极高的数据上

因此，HTTP/2 把**头部压缩**作为性能改进的一个重点

HTTP/2 没有采用传统的压缩算法，而是开发了专门的**HPACK**算法：在客户端和服务器两端建立字典，用索引号表示重复的字符串，还采用哈夫曼编码来压缩整数和字符串，可以达到 50%~90% 的高压缩率

### 二进制格式

HTTP/1 中的报文是纯文本形式，优点是“一目了然”，用最简单的工具就可以开发调试，非常方便

HTTP/2 不再使用肉眼可见的 ASCII 码，而是向下层的 TCP/IP 协议靠拢，全面采用二进制格式

这样虽然对人不友好，但却大大**方便了计算机的解析**。原来使用纯文本的时候容易出现多义性，比如大小写、空白字符、回车换行、多字少字等等，程序在处理时必须用复杂的状态机，效率低，还麻烦

而二进制里只有“0”和“1”，可以严格规定字段大小、顺序、标志位等格式，“对就是对，错就是错”，**解析起来没有歧义，实现简单，而且体积小、速度快，**做到“内部提效”

### 虚拟的“流”

消息的“碎片”到达目的地后应该怎么组装起来呢？

HTTP/2 为此定义了一个“**流**”（Stream）的概念，它是**二进制帧的双向传输序列**，同一个消息往返的帧会分配一个唯一的流 ID。你可以把它想象成是一个虚拟的“数据流”，在里面流动的是一串有先后顺序的数据帧，这些数据帧按照次序组装起来就是 HTTP/1 里的请求报文和响应报文

因为“流”是虚拟的，实际上并不存在，所以 HTTP/2 就可以在一个 TCP 连接上用“流”同时发送多个“碎片化”的消息，这就是常说的“**多路复用**”（ Multiplexing）——多个往返通信都复用一个连接来处理。

在“流”的层面上看，消息是一些有序的“帧”序列，而在“连接”的层面上看，消息却是乱序收发的“帧”。多个请求 / 响应之间没有了顺序关系，不需要排队等待，也就不会再出现“队头阻塞”问题，降低了延迟，大幅度提高了连接的利用率。
